{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c526e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6eb3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHolistic=mp.solutions.holistic\n",
    "mpDraw=mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86374235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw landmarks in image\n",
    "def drawLandmarks():\n",
    "    mpDraw.draw_landmarks(img,results.face_landmarks,mpHolistic.FACEMESH_CONTOURS,mpDraw.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),mpDraw.DrawingSpec(color=(80, 256, 121), thickness=2, circle_radius=2))\n",
    "    mpDraw.draw_landmarks(img,results.pose_landmarks,mpHolistic.POSE_CONNECTIONS,mpDraw.DrawingSpec(color=(80, 22, 10), thickness=1, circle_radius=1),mpDraw.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2))\n",
    "    mpDraw.draw_landmarks(img,results.left_hand_landmarks,mpHolistic.HAND_CONNECTIONS,mpDraw.DrawingSpec(color=(121, 22, 90), thickness=1, circle_radius=1),mpDraw.DrawingSpec(color=(255, 100, 112), thickness=2, circle_radius=2))\n",
    "    mpDraw.draw_landmarks(img,results.right_hand_landmarks,mpHolistic.HAND_CONNECTIONS,mpDraw.DrawingSpec(color=(250, 80, 10), thickness=1, circle_radius=1),mpDraw.DrawingSpec(color=(200, 50, 250), thickness=2, circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c123af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract keypoints of the features in image\n",
    "def extractKeypoints():\n",
    "    face=np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten()if results.face_landmarks else np.zeros(468*3)\n",
    "    leftHand=np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten()if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rightHand=np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten()if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    pose=np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten()if results.pose_landmarks else np.zeros(33*4)\n",
    "    return np.concatenate([face,leftHand,rightHand,pose])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2539ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sign_Images'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\"Sign_Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7deb8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for flatten datas\n",
    "dataPath = os.path.join('Sign_Data')\n",
    "\n",
    "#path for images\n",
    "imgPath= os.path.join('Sign_Image')\n",
    "\n",
    "signs=np.array([\"Hello\",\"Thank You\"])\n",
    "\n",
    "#30 video of each sign\n",
    "numSequences=30\n",
    "\n",
    "#length of each video\n",
    "sequenceLength=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb43e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sign in signs:\n",
    "    for sequence in range(numSequences):\n",
    "            try:\n",
    "                os.makedirs(os.path.join(dataPath,sign,str(sequence)))\n",
    "                os.makedirs(os.path.join(imgPath,sign,str(sequence)))\n",
    "            except:\n",
    "                pass\n",
    "# if not os.path.exists(\"Sign_Data\"):\n",
    "#     os.mkdir(\"Sign_Data\")\n",
    "# else:\n",
    "#     print(\"already exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac010925",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf83f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     inpt=input(print(\"Select which data are you collecting:\\n0: Hello \\n1: Thank you\"))\n",
    "#     if inpt == '0' or inpt == '1':\n",
    "#         choice=signs[int(inpt)]\n",
    "#         break\n",
    "#     else:\n",
    "#         print(\"Invalid input, please select again!!\")\n",
    "# choice   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77bbca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid=cv2.VideoCapture(0)\n",
    "with mpHolistic.Holistic() as holistic:\n",
    "\n",
    "    #taking label input \n",
    "    while True:\n",
    "        blankImg = np.zeros(shape=[512, 512, 3], dtype=np.uint8)\n",
    "        cv2.putText(blankImg,\"Select label: \", (10,50),cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(blankImg,\"0: Hello , 1: Thank You\", (10,100),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(blankImg,\"'ESC' to escape\", (10,150),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.imshow('Select label',blankImg)\n",
    "        inpt=cv2.waitKey(0)\n",
    "        if inpt == 48 or inpt == 49:\n",
    "            choice=signs[inpt-48]\n",
    "            cv2.destroyWindow('Select label')\n",
    "            break\n",
    "        else:\n",
    "            if inpt==27:\n",
    "                break\n",
    "            \n",
    "    #checking camera is opened or not and taking data    \n",
    "    while vid.isOpened() and inpt!=27 :\n",
    "        for sequence in range(numSequences):\n",
    "            for frameNum in range(sequenceLength+1):\n",
    "                #checks for user input to close the windows                \n",
    "                key=cv2.waitKey(1)\n",
    "                if key == 27 : #press esc to close the window\n",
    "                    break\n",
    "                    \n",
    "                success,img=vid.read()\n",
    "                \n",
    "                #checking if data is accessed or not from camera\n",
    "                if not success:\n",
    "                    break  \n",
    "                img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                # img.flags.writeable=False\n",
    "                results=holistic.process(img) \n",
    "                # img.flags.writeable=True     \n",
    "                img=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                #draws landmarks\n",
    "                drawLandmarks()\n",
    "                \n",
    "                #show feed for collecting datas and delays for 2 sec\n",
    "                if frameNum == 0: \n",
    "                    cv2.putText(img, 'STARTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0, 0), 2, cv2.LINE_AA)\n",
    "                    cv2.imshow('Collecting Datas', img)\n",
    "                    cv2.waitKey(2000)\n",
    "                    \n",
    "                #starts collecting datas    \n",
    "                else: \n",
    "                    cv2.putText(img, f\"Collecting Data for '{choice}' Video Number {sequence}\", (15,20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA) \n",
    "                    cv2.imshow('Collecting Datas', img)\n",
    "                    keypoints=extractKeypoints()  \n",
    "                    np.save(os.path.join(dataPath,choice,str(sequence),str(frameNum-1)),keypoints)\n",
    "                    jpgPath=os.path.join(imgPath,choice,str(sequence),str(frameNum-1))\n",
    "                    cv2.imwrite(f\"{jpgPath}.jpg\",img)\n",
    "            if key == 27 : #press esc to close the window\n",
    "                break        \n",
    "        if key == 27 : #press esc to close the window\n",
    "            break             \n",
    "            \n",
    "#releasing the port            \n",
    "vid.release() \n",
    "\n",
    "#destroying all opened windows using opencv\n",
    "cv2.destroyAllWindows()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd0883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f2250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae4229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
