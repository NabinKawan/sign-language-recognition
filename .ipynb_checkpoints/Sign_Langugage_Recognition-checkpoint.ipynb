{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c526e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6eb3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHolistic=mp.solutions.holistic\n",
    "mpDraw=mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86374235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw landmarks in image\n",
    "def drawLandmarks():\n",
    "    mpDraw.draw_landmarks(img,results.face_landmarks,mpHolistic.FACEMESH_CONTOURS,mpDraw.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),mpDraw.DrawingSpec(color=(80, 256, 121), thickness=2, circle_radius=2))\n",
    "    mpDraw.draw_landmarks(img,results.pose_landmarks,mpHolistic.POSE_CONNECTIONS,mpDraw.DrawingSpec(color=(80, 22, 10), thickness=1, circle_radius=1),mpDraw.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2))\n",
    "    mpDraw.draw_landmarks(img,results.left_hand_landmarks,mpHolistic.HAND_CONNECTIONS,mpDraw.DrawingSpec(color=(121, 22, 90), thickness=1, circle_radius=1),mpDraw.DrawingSpec(color=(255, 100, 112), thickness=2, circle_radius=2))\n",
    "    mpDraw.draw_landmarks(img,results.right_hand_landmarks,mpHolistic.HAND_CONNECTIONS,mpDraw.DrawingSpec(color=(250, 80, 10), thickness=1, circle_radius=1),mpDraw.DrawingSpec(color=(200, 50, 250), thickness=2, circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c123af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract keypoints of the features in image\n",
    "def extractKeypoints():\n",
    "    face=np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten()if results.face_landmarks else np.zeros(468*3)\n",
    "    leftHand=np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten()if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rightHand=np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten()if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    pose=np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten()if results.pose_landmarks else np.zeros(33*4)\n",
    "    return np.concatenate([face,leftHand,rightHand,pose])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2539ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sign_Images'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\"Sign_Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7deb8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for flatten datas\n",
    "dataPath = os.path.join('Sign_Data')\n",
    "\n",
    "#path for images\n",
    "imgPath= os.path.join('Sign_Image')\n",
    "\n",
    "signs=np.array([\"Hello\",\"Thank You\"])\n",
    "\n",
    "#30 video of each sign\n",
    "numSequences=30\n",
    "\n",
    "#length of each video\n",
    "sequenceLength=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb43e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sign in signs:\n",
    "    for sequence in range(numSequences):\n",
    "            try:\n",
    "                os.makedirs(os.path.join(dataPath,sign,str(sequence)))\n",
    "                os.makedirs(os.path.join(imgPath,sign,str(sequence)))\n",
    "            except:\n",
    "                pass\n",
    "# if not os.path.exists(\"Sign_Data\"):\n",
    "#     os.mkdir(\"Sign_Data\")\n",
    "# else:\n",
    "#     print(\"already exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac010925",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf83f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     inpt=input(print(\"Select which data are you collecting:\\n0: Hello \\n1: Thank you\"))\n",
    "#     if inpt == '0' or inpt == '1':\n",
    "#         choice=signs[int(inpt)]\n",
    "#         break\n",
    "#     else:\n",
    "#         print(\"Invalid input, please select again!!\")\n",
    "# choice   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77bbca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid=cv2.VideoCapture(0)\n",
    "with mpHolistic.Holistic() as holistic:\n",
    "\n",
    "    #taking label input \n",
    "     while True:\n",
    "        blankImg = np.zeros(shape=[512, 512, 3], dtype=np.uint8)\n",
    "        cv2.putText(blankImg,\"Select label: \", (10,50),cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(blankImg,\"0: Hello , 1: Thank You\", (10,100),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(blankImg,\"2: Hungry , 3: Food\", (10,150),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(blankImg,\"4: Hospital , 5: Washroom\", (10,200),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(blankImg,\"'ESC' to escape\", (10,250),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.imshow('Select label',blankImg)\n",
    "        inpt=cv2.waitKey(0)\n",
    "        if inpt == 48 or inpt == 49 or inpt == 50 or inpt == 51 or inpt == 52 or inpt == 53:\n",
    "            choice=signs[inpt-48]\n",
    "            cv2.destroyWindow('Select label')\n",
    "            break\n",
    "        else:\n",
    "            if inpt==27:\n",
    "                break\n",
    "            \n",
    "    #checking camera is opened or not and taking data    \n",
    "     while vid.isOpened() and inpt!=27 :\n",
    "        for sequence in range(numSequences):\n",
    "            for frameNum in range(sequenceLength+1):\n",
    "                #checks for user input to close the windows                \n",
    "                key=cv2.waitKey(1)                  \n",
    "                success,img=vid.read()\n",
    "                \n",
    "                #checking if data is accessed or not from camera\n",
    "                if not success:\n",
    "                    break  \n",
    "                img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                # img.flags.writeable=False\n",
    "                results=holistic.process(img) \n",
    "                # img.flags.writeable=True     \n",
    "                img=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                #draws landmarks\n",
    "                drawLandmarks()\n",
    "                \n",
    "                #show feed for collecting datas and delays for 2 sec\n",
    "                if frameNum == 0: \n",
    "                    cv2.putText(img, \"Press 'ESC' to escape\", (10,20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA) \n",
    "                    cv2.putText(img, 'press any key to conitnue', (10,60), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0, 0), 1, cv2.LINE_AA)\n",
    "                    cv2.imshow('Collecting Datas', img)\n",
    "                    key= cv2.waitKey(0)\n",
    "                    cv2.waitKey(1000)\n",
    "                    \n",
    "                #starts collecting datas    \n",
    "                else: \n",
    "                    cv2.putText(img, f\"Collecting Data for '{choice}' Video Number {sequence}\", (15,20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA) \n",
    "                    cv2.imshow('Collecting Datas', img)\n",
    "                    keypoints=extractKeypoints()  \n",
    "                    \n",
    "                    #saving flatten array to datapath\n",
    "                    np.save(os.path.join(dataPath,choice,str(sequence),str(frameNum-1)),keypoints)\n",
    "                    \n",
    "                    #saving image to image path\n",
    "                    jpgPath=os.path.join(imgPath,choice,str(sequence),str(frameNum-1))\n",
    "                    cv2.imwrite(f\"{jpgPath}.jpg\",img)\n",
    "                    key=2 #giving default value for key to avoid esc while taking data\n",
    "                \n",
    "                if key == 27 : #press esc to close the window\n",
    "                    break     \n",
    "\n",
    "            if key == 27 : #press esc to close the window\n",
    "                break        \n",
    "        if key == 27 : #press esc to close the window\n",
    "            break             \n",
    "            \n",
    "#releasing the port            \n",
    "vid.release() \n",
    "\n",
    "#destroying all opened windows using opencv\n",
    "cv2.destroyAllWindows()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abfd0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b53f2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b58714ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(signs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa789dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hello': 0, 'Thank You': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1af8e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for sign in signs:\n",
    "    for sequence in range(numSequences):\n",
    "        window = []\n",
    "        for frameNum in range(sequenceLength):\n",
    "            res = np.load(os.path.join(dataPath, sign, str(sequence), \"{}.npy\".format(frameNum)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8088e81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec0c5771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 30, 1662)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90d56a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.array([[[1,2],[3,4],[5,6]],[[1,2],[3,4],[5,6]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e5ea6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b00c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a1eb1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 30, 1662)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37b12529",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f2c8e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a7a24e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4553ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9fe2fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af4fac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e5b49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6320cabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1c22a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01366f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e48c007e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signs[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d353295f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ead1063c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd98f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
